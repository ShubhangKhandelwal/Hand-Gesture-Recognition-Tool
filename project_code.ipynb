{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c338dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "27a051e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "72e9dbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9bc2dd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('shubhang.png',photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "48890fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "shubhang_pic = cv2.imread('shubhang.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d56e543a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(shubhang_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "dc4b44ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shubhang_pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3f3fb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pic = shubhang_pic[100:400,100:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cd7b3a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('shubhangNew.png',new_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "508b5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pic[50:100] = [0,255,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d4ee4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1c9af387",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "561a85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow('my photo',photo)\n",
    "print(cv2.waitKey())\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ff9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cb505e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret,photo = cap.read()\n",
    "    cv2.imshow(\"my photo\",photo)\n",
    "    if cv2.waitKey(10)==13:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dc782e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "45ba9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo[:100,:100] = [0,255,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5973db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"my photo\",photo)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "98267be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo[:150,:150] = photo[100:250,150:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff471ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret,photo = cap.read()\n",
    "    print(photo.shape)\n",
    "    photo[:100,:100] = photo[150:250,200:300]\n",
    "    cv2.imshow(\"my pic\",photo)\n",
    "    if cv2.waitKey(10)==ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "720a745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res,pic = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05c6e4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5b6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e47ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5d2812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846cb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HandDetector(maxHands=1,detectionCon=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c93ba933",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,pic = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e20bb92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"my pic\",pic)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c23cfd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = detector.findHands(pic,draw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff98c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47652d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lmList': [[82, 498, 0],\n",
       "   [127, 491, -17],\n",
       "   [167, 473, -28],\n",
       "   [195, 458, -39],\n",
       "   [220, 442, -51],\n",
       "   [144, 395, -19],\n",
       "   [163, 349, -34],\n",
       "   [174, 322, -46],\n",
       "   [181, 297, -55],\n",
       "   [111, 387, -23],\n",
       "   [121, 333, -35],\n",
       "   [126, 301, -47],\n",
       "   [128, 275, -56],\n",
       "   [78, 392, -29],\n",
       "   [75, 341, -42],\n",
       "   [71, 310, -53],\n",
       "   [68, 284, -61],\n",
       "   [44, 408, -36],\n",
       "   [28, 371, -50],\n",
       "   [16, 348, -58],\n",
       "   [7, 326, -62]],\n",
       "  'bbox': (7, 275, 213, 223),\n",
       "  'center': (113, 386),\n",
       "  'type': 'Right'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1fdab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "644777f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 1]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 1]\n",
      "[1, 1, 1, 0, 1]\n",
      "[1, 1, 1, 0, 1]\n",
      "[1, 1, 1, 0, 1]\n",
      "[1, 1, 1, 0, 1]\n",
      "[1, 1, 1, 0, 1]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret,pic = cap.read()\n",
    "    hand = detector.findHands(pic,draw=False)\n",
    "    if hand!=[]:\n",
    "        detecthand = hand[0]\n",
    "        print(detector.fingersUp(detecthand))\n",
    "        cv2.imshow(\"my pic\",pic)\n",
    "    if cv2.waitKey(10)==13:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "355ae2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9000ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "411fe1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_url = urllib.request.urlopen('https://tkbkemdi6j.execute-api.ap-south-1.amazonaws.com/test/lock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e111d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"statusCode\": 200, \"body\": \"\\\\\"user locked\\\\\"\"}'\n"
     ]
    }
   ],
   "source": [
    "print(res_url.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "841bf273",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-0693273297ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfingersUp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cvzone\\HandTrackingModule.py\u001b[0m in \u001b[0;36mfingersUp\u001b[1;34m(self, myHand)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mfingers\u001b[0m \u001b[0mare\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \"\"\"\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mmyHandType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyHand\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mmyLmList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyHand\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lmList\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "detector.fingersUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26e7f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"my pic\",pic)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6efa54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r,pic = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28ec4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"my pic\",pic)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c070c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = detector.findHands(pic,draw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c24bd856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.fingersUp(hand[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62eb9bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lmList': [[603, 483, 0],\n",
       "  [555, 469, -11],\n",
       "  [526, 441, -20],\n",
       "  [526, 394, -34],\n",
       "  [557, 375, -44],\n",
       "  [524, 372, -3],\n",
       "  [491, 323, -17],\n",
       "  [477, 296, -26],\n",
       "  [465, 272, -33],\n",
       "  [556, 360, -13],\n",
       "  [537, 295, -37],\n",
       "  [525, 255, -52],\n",
       "  [515, 226, -60],\n",
       "  [588, 367, -25],\n",
       "  [581, 338, -53],\n",
       "  [583, 382, -48],\n",
       "  [584, 414, -36],\n",
       "  [619, 386, -39],\n",
       "  [608, 372, -57],\n",
       "  [603, 406, -50],\n",
       "  [600, 432, -40]],\n",
       " 'bbox': (465, 226, 154, 257),\n",
       " 'center': (542, 354),\n",
       " 'type': 'Left'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fb6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd516a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "locked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n",
      "unlocked\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    bo,pic = cap.read()\n",
    "    hand = detector.findHands(pic,draw=False)\n",
    "    \n",
    "    if hand!=[]:\n",
    "        fingers = detector.fingersUp(hand[0])\n",
    "        if fingers == [0,1,1,0,0]:\n",
    "            print(\"locked\")\n",
    "            \n",
    "        elif fingers == [0,1,1,1,0]:\n",
    "            print('unlocked')\n",
    "            \n",
    "        elif fingers ==[1,1,1,1,1]:\n",
    "            break\n",
    "            \n",
    "    cv2.imshow(\"my hand\",pic)\n",
    "    cv2.waitKey(20)==('q')\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54f4d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468f30ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-11-9139cf1e10fb>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9139cf1e10fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mface_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-9139cf1e10fb>\u001b[0m in \u001b[0;36mface_extractor\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfaces\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "        file_name_path = 'C://Users//Shubhang//Documents//ML_workshop_test_code_2023//Shubhang//image' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        \n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76987638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C://Users//Vimal Daga//Documents//ML_workshop_test_code_2023//vimal//'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-814f936b2e11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# print(a)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0monlyfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Create arrays for training data and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C://Users//Vimal Daga//Documents//ML_workshop_test_code_2023//vimal//'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "print(cv2.__version__)\n",
    "# Get the training data we previously made\n",
    "data_path = 'C://Users//Vimal Daga//Documents//ML_workshop_test_code_2023//vimal//'\n",
    "# a=listdir('d:/faces')\n",
    "# print(a)\n",
    "# \"\"\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "# \n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "# model=cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create() \n",
    "# Initialize facial recognizer\n",
    "#model = cv2.face_LBPHFaceRecognizer.create()\n",
    "# model=cv2.f\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ade603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "import webbrowser as wb\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image, face = face_detector(frame)\n",
    "\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = model.predict(face)\n",
    "        print(results)\n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "\n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "\n",
    "        if confidence > 80:\n",
    "            #os.system(\"docker run  -d -i -t --name vimalos ubuntu:latest\")\n",
    "            cv2.putText(image, \"Hey Vimal\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            # break\n",
    "            #webbrowser.open('http://google.com/')\n",
    "\n",
    "        else:\n",
    "            cv2.putText(image, \"i dont know\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ipd.Audio('violin.wav', autoplay=True )\n",
    "#wb.open('https://www.google.com/')\n",
    "\n",
    "# ipd.Audio('violin.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445c2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e2f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
